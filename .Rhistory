head(bpb_av)
source_folder <- "/Volumes/HD-B1/BIDS/derivatives/afni"
hc_list <- paste0("/Volumes/HD-B1/BIDS/derivatives/afni/sub-", 34:70, ".results")
hc_list <- c(hc_list, paste0("/Volumes/HD-B1/extra-proc/sub-", 86:99, ".results"))
# Apply the function to each folder
hc_results <- lapply(hc_list, function(dir) read_1D(dir, target_file))
# Convert list to matrix and compute column-wise mean
num_matrix <- do.call(rbind, hc_results)
hc_av <- colMeans(num_matrix)  # Compute element-wise mean
head(hc_av)
bpb_av <- colMeans(num_matrix)  # Compute element-wise mean
csv_path <- "/Users/kaankeskin/projects/MultGroup_WC/REPLICATION/data/bp_array.csv"
write.csv(bpb_av, csv_path, row.names=FALSE)
csv_path <- "/Users/kaankeskin/projects/MultGroup_WC/REPLICATION/data/hc_array.csv"
write.csv(hc_av, csv_path, row.names = FALSE)
# Convert list to matrix and compute column-wise mean
num_matrix <- do.call(rbind, bpb_results)
bpb_av <- colMeans(num_matrix)  # Compute element-wise mean
bpb_av
bpb_av <- colMeans(num_matrix)  # Compute element-wise mean
csv_path <- "/Users/kaankeskin/projects/MultGroup_WC/REPLICATION/data/bp_array.csv"
write.csv(bpb_av, csv_path, row.names=FALSE)
# Apply the function to each folder
hc_results <- lapply(hc_list, function(dir) read_1D(dir, target_file))
# Convert list to matrix and compute column-wise mean
num_matrix <- do.call(rbind, hc_results)
hc_av <- colMeans(num_matrix)  # Compute element-wise mean
csv_path <- "/Users/kaankeskin/projects/MultGroup_WC/REPLICATION/data/hc_array.csv"
write.csv(hc_av, csv_path, row.names = FALSE)
library(R.matlab); library(tidyverse)
#
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/pe_array.mat")
#
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/pe_array.mat")
dat[:,1:60]
dat[,1:60]
dat$merged.matrix(,1:60)
dat$merged.matrix[,1:60]
pe_mat <- dat$merged.matrix[,1:60]
group <- ifelse(pe_mat[,61],"sz","hc")
ifelse(dat$merged.matrix[,61],"sz","hc")
group <- ifelse(dat$merged.matrix[,61],"sz","hc")
task <- repmat(c(1,2,3),each=20)
task <- rep(c(1,2,3),each=20)
task
str(pe_mat)
str(group)
str(task)
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:52  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Check structure
str(long_pe)
head(long_pe)
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
library(lme4)
anova_model <- lmer(PE ~ Group * Task + (1|Subject), data = long_pe)
anova(anova_model)
# Loading libraries
library(R.matlab); library(tidyverse)
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/normalized_pe_array.mat")
pe_mat <- dat$merged.matrix[,1:60]
group <- ifelse(dat$merged.matrix[,61],"sz","hc")
task <- rep(c(1,2,3),each=20)
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:52  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Check structure
str(long_pe)
head(long_pe)
library(lme4)
anova_model <- lmer(PE ~ Group * Task + (1|Subject), data = long_pe)
anova(anova_model)
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
pe_mat
library(R.matlab); library(tidyverse)
#
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/pe_array.mat")
#dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/normalized_pe_array.mat")
pe_mat <- dat$merged.matrix[,1:60]
group <- ifelse(dat$merged.matrix[,61],"sz","hc")
task <- rep(c(1,2,3),each=20)
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:52  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Check structure
str(long_pe)
head(long_pe)
library(lme4)
anova_model <- lmer(PE ~ Group * Task + (1|Subject), data = long_pe)
anova(anova_model)
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/pe_array.mat")
#dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/normalized_pe_array.mat")
pe_mat <- dat$merged.matrix[,1:60]
group <- factor(ifelse(dat$merged.matrix[,61],"sz","hc"))
task <- factor(rep(c(1,2,3),each=20))
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:52  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Check structure
str(long_pe)
plot(density(long_pe$PE))
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
library(emmeans)
# Fit mixed ANOVA model again
library(lme4)
anova_model <- lmer(PE ~ Group * Task + (1|Subject), data = long_pe)
# Estimated Marginal Means (EMMs) for Task within each Group
task_emmeans <- emmeans(anova_model, pairwise ~ Task | Group, adjust = "bonferroni")
# Show pairwise comparisons
task_emmeans
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
# Estimated Marginal Means (EMMs) for Task within each Group
task_emmeans <- emmeans(anova_model, pairwise ~ Task | Group, adjust = "bonferroni")
# Show pairwise comparisons
task_emmeans
task_emmeans <- emmeans(anova_model, pairwise ~ Group | Task, adjust = "bonferroni")
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
task_emmeans <- emmeans(anova_model, pairwise ~ Group , adjust = "bonferroni")
# Show pairwise comparisons
task_emmeans
summary(anova_model)
library(emmeans)
# Estimated Marginal Means (EMMs) for Task within each Group
task_emmeans <- emmeans(anova_model, pairwise ~ Task | Group, adjust = "bonferroni")
# Show pairwise comparisons
task_emmeans
load("/Volumes/HD-B1/EIB/Rho_Med.RData")
load("/Volumes/HD-B1/EIB/Rho_Med.RData")
load("/Volumes/HD-B1/EIB/Rho_Med.Rdata")
file.exists("/Volumes/HD-B1/EIB/Rho_Med.Rdata")
library(stringr)
br <- readMat("/Users/kaank/OneDrive/Belgeler/GitHub/MYELIN_2/DATA/myDataParcels.mat")
library(R.matlab)
library(tidyverse)
library(ggseg)
library(stringr)
br <- readMat("/Users/kaank/OneDrive/Belgeler/GitHub/MYELIN_2/DATA/myDataParcels.mat")
br <- readMat("/Users/kaankeskin/projects/MYELIN_2/DATA/myDataParcels.mat")
regions <- matrix(unlist(br$myDataParcels[, 1]), 1)
suffixtoremove <- "_ROI"
modifiedstrings <- character(length(regions))
group <- matrix(unlist(br$myDataParcels[, 2]), 1)
group <- ifelse(uni,1,2)
br <- readMat("/Users/kaankeskin/projects/MYELIN_2/DATA/myDataParcels.mat")
regions <- matrix(unlist(br$myDataParcels[, 1]), 1)
suffixtoremove <- "_ROI"
modifiedstrings <- character(length(regions))
group <- matrix(unlist(br$myDataParcels[, 2]), 1)
group
plot_brain <- data.frame(region = matrix(modifiedstrings),
group = factor(matrix(group)),
HEMIS = c(rep("R", 180),rep("L",180)),
region_to_fill = factor(c(1:360)),
stringsAsFactors = FALSE
)
for (i in seq_along(regions)) {
modifiedstrings[i] <- str_replace(regions[i], suffixtoremove, "")
}
for (i in c(1:180)) {
prefixToRemove = "R_"
plot_brain$region[i] <- sub(paste0("^", prefixToRemove), "", modifiedstrings[i])
}
for (i in c(181:360)) {
prefixToRemove = "L_"
plot_brain$region[i] <- sub(paste0("^", prefixToRemove), "", modifiedstrings[i])
}
library(ggseg) ; library(ggsegGlasser) ; library(rethinking)
# install.packages("devtools")
devtools::install_github("LCBC-UiO/ggsegGlasser")
library(ggseg) ; library(ggsegGlasser) ; library(rethinking)
plot_brain$myelin = myelin
br
dat <- readMat('/Users/kaankeskin/OneDrive/Belgeler/GitHub/MYELIN_2/DATA/7T_final.mat')
myelin <- colMeans(dat$myelin.replication)
plot_brain$myelin = myelin
plot_brain
myelin_brain <-plot_brain  %>% ggplot() + geom_brain( atlas = glasser,
show.legend = TRUE,
hemi = "right" ,
mapping = aes(fill = myelin) ) +
scale_fill_gradient2(low = "#DF37AE",
high = "#4DB3F7",
mid = "#DCE3F5", midpoint = 1.83,
breaks = c(1.7, 1.9, 2.3),
labels = c("Transmodal","","Unimodal")) +
theme_classic()+
theme(legend.position = "bottom",
legend.text = element_text(size = 10),
axis.line = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.ticks.y = element_blank(),
axis.text.y = element_blank())
myelin_brain
myelin_brain
group_brain <- plot_brain  %>% ggplot() + geom_brain( atlas = glasser,
show.legend = FALSE,
hemi = "right" ,
mapping = aes(fill = group) ) +
scale_fill_brain2(palette=c("#4DB3F7", "#DF37AE")) +
theme_classic()+
theme(legend.position = "bottom",
legend.text = element_text(size = 10),
axis.line = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.ticks.y = element_blank(),
axis.text.y = element_blank())
group_brain
ggarrange(plotlist = list(group_brain,myelin_brain),ncol=1) %>%
ggpubr::ggexport(filename = "/Users/kaankeskin/projects/MYELIN_2/FIGURES/test_brain.png",width = 1200,height = 1200,res=300)
library(ggpubr)
ggarrange(plotlist = list(group_brain,myelin_brain),ncol=1) %>%
ggpubr::ggexport(filename = "/Users/kaankeskin/projects/MYELIN_2/FIGURES/test_brain.png",width = 1200,height = 1200,res=300)
source_folder = "/Users/kaankeskin/projects/MYELIN_2/"
use_python("/opt/anaconda3/envs/neurolib_env/bin/python")
library(reticulate)
use_python("/opt/anaconda3/envs/neurolib_env/bin/python")
np <- import("numpy")
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
merge_matrices <- function(array) {
# Initialize empty matrices to store the merged results
merged_acw_static_firing_matrix <- NULL
merged_acw_dynamic_firing_matrix <- NULL
merged_gscorr_fmri_matrix <- NULL
merged_gscorr_firing_matrix <- NULL
# Loop through each element in the list and row bind the matrices
for (i in seq_along(array)) {
merged_acw_static_firing_matrix <- rbind(merged_acw_static_firing_matrix, array[[i]]$acw_static_firing_matrix)
merged_acw_dynamic_firing_matrix <- rbind(merged_acw_dynamic_firing_matrix, array[[i]]$acw_dynamic_firing_matrix)
merged_gscorr_fmri_matrix <- rbind(merged_gscorr_fmri_matrix, array[[i]]$gscorr_fmri_matrix)
merged_gscorr_firing_matrix <- rbind(merged_gscorr_firing_matrix, array[[i]]$gscorr_firing_matrix)
}
# Return a list of merged matrices
return(list(
acw_static_firing_matrix = merged_acw_static_firing_matrix,
acw_dynamic_firing_matrix = merged_acw_dynamic_firing_matrix,
gscorr_fmri_matrix = merged_gscorr_fmri_matrix,
gscorr_firing_matrix = merged_gscorr_firing_matrix
))
}
no_topo <- merge_matrices(np$load(paste0(source_folder,"DATA/notopo_v3.npy"),allow_pickle = TRUE))
str(no_topo)
# Empirical
library(R.matlab)
dat <- readMat(paste0(source_folder,"/DATA/7T_final.mat"))
dat
dat$ACW0.GS.replication
as.matrix(dat$ACW0.GS.replication)
str(dat$ACW0.GS.replication)
str(no_topo)
dat_list <- list()
dat_list <- list()
dat_list$myelin <- dat$myelin.replication
dat_list$ACW0 <- dat$ACW0.GS.replication
dat_list$myelin <- dat$GSCORR.GS.replication
dat_list$myelin <- dat$myelin.replication
dat_list$ACW <- dat$ACW0.GS.replication
dat_list$GSCORR <- dat$GSCORR.GS.replication
level_list = list()
ylab_list = list()
parts=c("myelin", "ACW", "GSCORR")
level_list[[parts[1]]]=c("TransSelf","TransNonself","UniSelf" , "UniNonself")
level_list[[parts[2]]]=c("TransSelf","TransNonself","UniSelf" , "UniNonself")
level_list[[parts[3]]]=c("TransSelf","TransNonself","UniSelf" , "UniNonself")
ylab_list[[parts[1]]] = c("Myelin")
ylab_list[[parts[2]]] = c("ACW")
ylab_list[[parts[3]]] = c("GSCORR")
empirical <- calculate_prs(dat_list, parts = parts,levels=level_list,y_labels = ylab_list,textsize=6,sign_size=4,ast_size = 6,title = "", ylab_size= 12, method = "rowMeans")
library(NeuroMyelFC)
dat <- readMat(paste0(source_folder,"/DATA/7T_final.mat"))
dat_list <- list()
dat_list$myelin <- dat$myelin.replication
dat_list$ACW <- dat$ACW0.GS.replication
dat_list$GSCORR <- dat$GSCORR.GS.replication
level_list = list()
ylab_list = list()
parts=c("myelin", "ACW", "GSCORR")
level_list[[parts[1]]]=c("TransSelf","TransNonself","UniSelf" , "UniNonself")
level_list[[parts[2]]]=c("TransSelf","TransNonself","UniSelf" , "UniNonself")
level_list[[parts[3]]]=c("TransSelf","TransNonself","UniSelf" , "UniNonself")
ylab_list[[parts[1]]] = c("Myelin")
ylab_list[[parts[2]]] = c("ACW")
ylab_list[[parts[3]]] = c("GSCORR")
empirical <- calculate_prs(dat_list, parts = parts,levels=level_list,y_labels = ylab_list,textsize=6,sign_size=4,ast_size = 6,title = "", ylab_size= 12, method = "rowMeans")
empirical
empirical$interaction_plots
empirical$interaction_plots$ACW
empirical$interaction_plot$myelin
empirical <- calculate_prs(dat_list, parts = parts,levels=level_list,y_labels = ylab_list,textsize=6,sign_size=4,ast_size = 6,title = "", ylab_size= 12, method = "rowMeans")
ggpubr::ggarrange(plotlist = empirical$interaction_plots, nrow = 1, ncol = 3
)%>% ggpubr::ggexport(filename = paste0(source_folder,"FIGURES/empirical.png"),height = 400, width = 1200, res= 150)
library(tidyverse)
empirical <- calculate_prs(dat_list, parts = parts,levels=level_list,y_labels = ylab_list,textsize=6,sign_size=4,ast_size = 6,title = "", ylab_size= 12, method = "rowMeans")
ggpubr::ggarrange(plotlist = empirical$interaction_plots, nrow = 1, ncol = 3
)%>% ggpubr::ggexport(filename = paste0(source_folder,"FIGURES/empirical.png"),height = 400, width = 1200, res= 150)
library(magick)
# Example PNG files
file3 <- paste0(source_folder,"FIGURES/empirical.png")
file4 <- paste0(source_folder,"FIGURES/recur_group_v3.png")
# Read the PNG files
image3 <- image_read(file3) %>% image_resize(geometry = "1200x")
image4 <- image_read(file4) %>% image_resize(geometry = "1200x")
image_w <- image_blank(width=1200, height = 200, color = "white")
fig_5_merged <- image_append(c(image3,image_w, image4), stack = TRUE)
fig_5_merged
fig_5_merged
png(paste0(source_folder,"FIGURES/fig_5_new3.png"), width = 1200, height = 1400, res = 150)
plot(fig_5_merged)
text(x = 0, y = 1350, labels = "A", xpd = NA, cex=1.5, font=2)
text(x = 0, y = 1150, labels = "B", xpd = NA, cex=1.5, font=2)
text(x = 550, y = 1100, labels = "Empirical Results", xpd = NA, cex=1.5, font=1)
text(x = 550, y = 900, labels = "Simulation Results", xpd = NA, cex=1.5, font=1)
text(x = 0, y = 770, labels = "C", xpd = NA, cex=1.5, font=2)
dev.off()
plot(fig_5_merged)
text(x = 0, y = 1350, labels = "A", xpd = NA, cex=1.5, font=2)
text(x = 0, y = 1150, labels = "B", xpd = NA, cex=1.5, font=2)
text(x = 550, y = 1400, labels = "Empirical Results", xpd = NA, cex=1.5, font=1)
text(x = 550, y = 650, labels = "Simulation Results", xpd = NA, cex=1.5, font=1)
text(x = 0, y = 450, labels = "C", xpd = NA, cex=1.5, font=2)
dev.off()
png(paste0(source_folder,"FIGURES/fig_5_new3.png"), width = 1200, height = 1400, res = 150)
plot(fig_5_merged)
text(x = 0, y = 1350, labels = "A", xpd = NA, cex=1.5, font=2)
text(x = 0, y = 450, labels = "B", xpd = NA, cex=1.5, font=2)
text(x = 550, y = 1400, labels = "Empirical Results", xpd = NA, cex=1.5, font=1)
text(x = 550, y = 650, labels = "Simulation Results", xpd = NA, cex=1.5, font=1)
text(x = 0, y = 250, labels = "C", xpd = NA, cex=1.5, font=2)
dev.off()
fig_5_merged <- image_append(c(image3,image_w, image4), stack = TRUE)
png(paste0(source_folder,"FIGURES/fig_5_new3.png"), width = 1200, height = 1400, res = 150)
plot(fig_5_merged)
text(x = 0, y = 1350, labels = "A", xpd = NA, cex=1.5, font=2)
text(x = 0, y = 750, labels = "B", xpd = NA, cex=1.5, font=2)
text(x = 550, y = 1400, labels = "Empirical Results", xpd = NA, cex=1.5, font=1)
text(x = 550, y = 850, labels = "Simulation Results", xpd = NA, cex=1.5, font=1)
text(x = 0, y = 4000, labels = "C", xpd = NA, cex=1.5, font=2)
dev.off()
png(paste0(source_folder,"FIGURES/fig_5_new3.png"), width = 1200, height = 1400, res = 150)
plot(fig_5_merged)
text(x = 0, y = 1350, labels = "A", xpd = NA, cex=1.5, font=2)
text(x = 0, y = 750, labels = "B", xpd = NA, cex=1.5, font=2)
text(x = 550, y = 1400, labels = "Empirical Results", xpd = NA, cex=1.5, font=1)
text(x = 550, y = 850, labels = "Simulation Results", xpd = NA, cex=1.5, font=1)
text(x = 0, y = 400, labels = "C", xpd = NA, cex=1.5, font=2)
dev.off()
library(R.matlab); library(tidyverse); library(reshape2)
setwd("/Users/kaankeskin/projects/sch_pe/")
# Microsoft
setwd("C:/Users/kaank/OneDrive/Belgeler/GitHub/sch_pe/")
library(R.matlab); library(tidyverse); library(reshape2)
setwd("/Users/kaankeskin/projects/sch_pe/")
dat <- list(readMat("./data/processed/pe_array2.mat"), # Cemre RW PE
readMat("./data/processed/x2_array.mat"), # HGF X2
readMat("./data/processed/x3_array.mat"), # HGF X3
readMat("./data/processed/x2_pe_array.mat"), # HGF low level PE
readMat("./data/processed/x3_pe_array.mat"), # HGF high level PE
readMat("./data/processed/alfa2_array.mat"), # learning rate level 2
readMat("./data/processed/alfa3_array.mat"), # learning rate level 3
readMat("./data/processed/rw_pe.mat") # RW model PE from TAPAS
)
subj_table <- read.csv("./data/raw/subjects_list.csv")
dat[[1]]
library(R.matlab); library(tidyverse); library(reshape2)
setwd("/Users/kaankeskin/projects/sch_pe/")
# Microsoft
#setwd("C:/Users/kaank/OneDrive/Belgeler/GitHub/sch_pe/")
#
dat <- list(readMat("./data/processed/normalized_pe_array2.mat"), # Cemre RW PE
readMat("./data/processed/x2_array.mat"), # HGF X2
readMat("./data/processed/x3_array.mat"), # HGF X3
readMat("./data/processed/x2_pe_array.mat"), # HGF low level PE
readMat("./data/processed/x3_pe_array.mat"), # HGF high level PE
readMat("./data/processed/alfa2_array.mat"), # learning rate level 2
readMat("./data/processed/alfa3_array.mat"), # learning rate level 3
readMat("./data/processed/rw_pe.mat") # RW model PE from TAPAS
)
dat[[1]]
subj_table <- read.csv("./data/raw/subjects_list.csv")
#subj_table <- subset(subj_table, !(subj %in% c(9, 44)))
#dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/normalized_pe_array.mat")
convert_to_long <- function(dat, subj_table) {
# Extract PE matrix (first 60 columns) and group information (column 61)
pe_mat <- dat$merged.matrix[,1:60]
group <- factor(ifelse(dat$merged.matrix[,61], "sz", "hc"))
task <- factor(rep(1:3, each = 20))  # Assuming 3 tasks with 20 trials each
sex <- factor(ifelse(subj_table$sex, "M", "F"))
# Convert PE matrix to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- seq_len(nrow(pe_mat))  # Assign unique IDs to subjects
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Convert Trial variable to numeric
#long_pe$Trial <- as.numeric(gsub("V", "", long_pe$Trial))  # Remove "V" prefix if needed
# Add Group information (repeat for each trial)
long_pe$Group <- rep(group, each = ncol(pe_mat))
# Add Task information (repeat for each subject)
long_pe$Task <- rep(task, times = nrow(pe_mat))
# Add Sex information (repeat for each trial)
long_pe$Sex <- rep(sex, each = ncol(pe_mat))
return(long_pe)
}
# Usage
long_pe_list <- lapply(dat, convert_to_long, subj_table = subj_table)
plot(density(long_pe_list[[1]]))
plot(density(long_pe_list[[1]]$PE))
long_pe_list[[1]]$PE
abs(min(long_pe_list[[1]]$PE))
long_pe_list[[1]]$PE + abs(min(long_pe_list[[1]]$PE))
long_pe_list[[1]]$PE_shifted <- long_pe_list[[1]]$PE + abs(min(long_pe_list[[1]]$PE)) + 1.2
plot(density(long_pe_list[[1]]$PE_shifted))
long_pe_list[[1]]$PE_shifted <- long_pe_list[[1]]$PE + abs(min(long_pe_list[[1]]$PE)) + 0.01
plot(density(long_pe_list[[1]]$PE_shifted))
long_pe_list[[1]]$PE_shifted <- long_pe_list[[1]]$PE + abs(min(long_pe_list[[1]]$PE)) + 0.1
plot(density(long_pe_list[[1]]$PE_shifted))
plot(density(long_pe_list[[1]]$PE_shifted))
long_pe_list[[1]]$PE_shifted <- long_pe_list[[1]]$PE + abs(min(long_pe_list[[1]]$PE)) + 0.15
plot(density(long_pe_list[[1]]$PE_shifted))
long_pe_list[[1]]$PE_shifted <- long_pe_list[[1]]$PE + abs(min(long_pe_list[[1]]$PE)) + 0.2
plot(density(long_pe_list[[1]]$PE_shifted))
long_pe_list[[1]]$PE_shifted <- long_pe_list[[1]]$PE + abs(min(long_pe_list[[1]]$PE)) + 0.25
plot(density(long_pe_list[[1]]$PE_shifted))
library(lme4)
gamma_model <- glmer(PE_shifted ~ Group + Task + (1 | Subject),
data = long_pe_list[[1]],
family = Gamma(link = "log"),
control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)))
summary(gamma_model)
plot(dat[[1]])
plot(dat[[1]]$merged.matrix[1,1:60])
plot(x=c(1:60),y=dat[[1]]$merged.matrix[1,1:60])
help(plot)
plot(x=c(1:60),y=dat[[1]]$merged.matrix[1,1:60],type="l")
gamma_model <- glmer(PE_shifted ~ Group * Task + (1 | Subject),
data = long_pe_list[[1]],
family = Gamma(link = "log"),
control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)))
summary(gamma_model)
gamma_model <- glmer(PE_shifted ~ Group + Task + (1 | Subject),
data = long_pe_list[[1]],
family = Gamma(link = "log"),
control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)))
summary(gamma_model)
T_raw <- read.csv("./data/raw/response.csv")
T <- T_raw[T_raw$denekId %in% subj_table$task.id,]
T_aslihan <- read.csv("./data/processed/aslihan_filtered.csv")
T <- rbind(T,T_aslihan)
# Control the number of subject
#sum(T$sayac==59)
T_last <- T[,c(2,3,4,5)]
T_last$group <- rep(subj_table$group,each=60)
T_last$phase <- cut(
T_last$sayac,
breaks = c(0,19,39,59),
labels = c("1", "2", "3"),
include.lowest = TRUE
)
library(lme4)
T_last$yatirim <- factor(T_last$yatirim)
#T_last$rakip <- factor(T_last$rakip)
T_last$group <- factor(T_last$group)
T_last$phase <- factor(T_last$phase)
# Addition of the interaction doesn't improve the model
model_simple <- glmer(yatirim ~ group + phase + (1 | denekId),
data = T_last,
family = binomial(link = "logit"))
summary(model_simple)
