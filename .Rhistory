img34 <- image_append(c(img3, img4), stack = FALSE)
img1234 <- image_append(c(img12, img34), stack = TRUE)
img1234
merged_img <- image_append(c(img1234,bar),stack = FALSE)
merged_img
img1234
bar
img1 <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/part1.jpg") %>% image_resize("x300")
img2 <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/part2.jpg") %>% image_resize("x300")
img3 <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/part3.jpg") %>% image_resize("x300")
img4 <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/part4.jpg") %>% image_resize("x300")
bar <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/scale_page.png") %>% image_resize("x600")
filler <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/black_rectangle.png")
img12 <- image_append(c(img1, img2), stack = FALSE)
img34 <- image_append(c(img3, img4), stack = FALSE)
img1234 <- image_append(c(img12, img34), stack = TRUE)
merged_img <- image_append(c(img1234,bar),stack = FALSE)
merged_img
library(magick)
library(tidyverse)
img1 <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/part1.jpg") %>% image_resize("x300")
img2 <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/part2.jpg") %>% image_resize("x300")
img3 <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/part3.jpg") %>% image_resize("x300")
img4 <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/part4.jpg") %>% image_resize("x300")
bar <- image_read("/Users/kaankeskin/projects/AchStat/cerebellum/scale_page.png") %>% image_resize("x600")
img12 <- image_append(c(img1, img2), stack = FALSE)
img34 <- image_append(c(img3, img4), stack = FALSE)
img1234 <- image_append(c(img12, img34), stack = TRUE)
merged_img <- image_append(c(img1234,bar),stack = FALSE)
image_write(merged_img, path = "/Users/kaankeskin/projects/AchStat/cerebellum/merged_image.png", format = "png")
# Library
library(ggplot2)
library(dplyr)
library(rstatix)
library(ggpubr)
# Importing data
bpb_core <- scan("/Volumes/HD-B1/BPB_proc/bpb_subjects_core.1D",what = numeric())
bpb_periphery <- scan("/Volumes/HD-B1/BPB_proc/bpb_subjects_periphery.1D",what = numeric())
mdd_core <- scan("/Volumes/HD-B1/extra-proc/mdd_subjects_core.1D",what = numeric())
mdd_periphery <- scan("/Volumes/HD-B1/extra-proc/mdd_subjects_periphery.1D",what = numeric())
hc_core <- scan("/Volumes/HD-B1/extra-proc/hc_subjects_core.1D",what = numeric())
hc_periphery <- scan("/Volumes/HD-B1/extra-proc/hc_subjects_periphery.1D",what = numeric())
hc_periphery <- scan("/Volumes/HD-B1/extra-proc/hc_subjects_periphery.1D",what = numeric())
# Importing data
bpb_core <- scan("/Volumes/HD-B1/BPB_proc/bpb_subjects_core.1D",what = numeric())
bpb_periphery <- scan("/Volumes/HD-B1/BPB_proc/bpb_subjects_periphery.1D",what = numeric())
mdd_core <- scan("/Volumes/HD-B1/extra-proc/mdd_subjects_core.1D",what = numeric())
mdd_periphery <- scan("/Volumes/HD-B1/extra-proc/mdd_subjects_periphery.1D",what = numeric())
hc_core <- scan("/Volumes/HD-B1/extra-proc/hc_subjects_core.1D",what = numeric())
hc_periphery <- scan("/Volumes/HD-B1/extra-proc/hc_subjects_periphery.1D",what = numeric())
bpb_len <- length(bpb_core)
mdd_len <- length(mdd_core)
hc_len <- length(hc_core)
# Tidying data to long format
data_long <- data.frame(
value = c(bpb_core,bpb_periphery,mdd_core,mdd_periphery,hc_core,hc_periphery),
topo = c(rep(c("C","P"),each=bpb_len), rep(c("C","P"),each=mdd_len), rep(c("C","P"),each=hc_len)),
group = c(rep("BP", bpb_len*2), rep("MDD",mdd_len*2), rep("HC", hc_len*2))
)
# Filter data for topo C and P
data_filtered <- data_long %>% filter(topo %in% c("C", "P"))
# Compute max values per topo for y-position of significance annotations
max_values <- data_filtered %>%
group_by(topo) %>%
summarise(y_max = max(value, na.rm = TRUE))  # Ensures itâ€™s numeric
# Perform t-test for each topo separately
stat_test <- data_filtered %>%
group_by(topo) %>%
t_test(value ~ group,var.equal = FALSE ) %>% # Welch's Method
adjust_pvalue(method = "bonferroni") %>%
add_significance()
stat_test
stat_test <- stat_test %>%
left_join(max_values, by = "topo") %>%
mutate(y.position = y_max + 0.05 + (row_number() - 1) * 0.05)  # Adjust incrementally
# Print test results to check correctness
print(stat_test)
# Violin plot with statistical annotations
p <- ggplot(data_filtered, aes(x = group, y = value, fill = group)) +
geom_violin(trim = FALSE, alpha = 0.6) +
geom_jitter(width = 0.1, alpha = 0.5) +
facet_wrap(~topo) +
stat_pvalue_manual(
stat_test,
label = "p.adj.signif",
inherit.aes = FALSE,
mapping = aes(xmin = group1, xmax = group2, y.position = y.position)
) +
theme_bw() +  # Ensures a white background
labs(title = "", x = "Group", y = "Value") +
theme(legend.position = "none")
p
install.packages("haven")  # Install if not already installed
library(haven)
dat <- read_sav("/Users/kaankeskin/Downloads/alzheimer.sav")
dat
View(dat)
library(reticulate)
library(NeuroMyelFC)
source_folder <- "/Volumes/HD-B1/BPB_proc"
bpb_list <- list.dirs(path = source_folder, recursive = FALSE)
# Function to read a specific .1D file in each directory
read_1D <- function(dir_path, filename) {
# Construct full file path
file_path <- file.path(paste0(dir_path,"/Zscore_data_bandpass"), "glasser_all.1D")
# Check if the file exists
if (!file.exists(file_path)) {
return(NULL)  # Return NULL if the file is missing
}
# Read the .1D file (as numeric data)
file_data <- scan(file_path, what = numeric(), quiet = TRUE)
return(file_data)
}
# Apply the function to each folder
bpb_results <- lapply(bpb_list, function(dir) read_1D(dir, target_file))
# Assign folder names as list names
names(bpb_results) <- basename(bpb_list)
# Convert list to matrix and compute column-wise mean
num_matrix <- do.call(rbind, bpb_results)
bpb_av <- colMeans(num_matrix)  # Compute element-wise mean
head(bpb_av)
source_folder <- "/Volumes/HD-B1/BIDS/derivatives/afni"
hc_list <- paste0("/Volumes/HD-B1/BIDS/derivatives/afni/sub-", 34:70, ".results")
hc_list <- c(hc_list, paste0("/Volumes/HD-B1/extra-proc/sub-", 86:99, ".results"))
# Apply the function to each folder
hc_results <- lapply(hc_list, function(dir) read_1D(dir, target_file))
# Convert list to matrix and compute column-wise mean
num_matrix <- do.call(rbind, hc_results)
hc_av <- colMeans(num_matrix)  # Compute element-wise mean
head(hc_av)
bpb_av <- colMeans(num_matrix)  # Compute element-wise mean
csv_path <- "/Users/kaankeskin/projects/MultGroup_WC/REPLICATION/data/bp_array.csv"
write.csv(bpb_av, csv_path, row.names=FALSE)
csv_path <- "/Users/kaankeskin/projects/MultGroup_WC/REPLICATION/data/hc_array.csv"
write.csv(hc_av, csv_path, row.names = FALSE)
# Convert list to matrix and compute column-wise mean
num_matrix <- do.call(rbind, bpb_results)
bpb_av <- colMeans(num_matrix)  # Compute element-wise mean
bpb_av
bpb_av <- colMeans(num_matrix)  # Compute element-wise mean
csv_path <- "/Users/kaankeskin/projects/MultGroup_WC/REPLICATION/data/bp_array.csv"
write.csv(bpb_av, csv_path, row.names=FALSE)
# Apply the function to each folder
hc_results <- lapply(hc_list, function(dir) read_1D(dir, target_file))
# Convert list to matrix and compute column-wise mean
num_matrix <- do.call(rbind, hc_results)
hc_av <- colMeans(num_matrix)  # Compute element-wise mean
csv_path <- "/Users/kaankeskin/projects/MultGroup_WC/REPLICATION/data/hc_array.csv"
write.csv(hc_av, csv_path, row.names = FALSE)
library(R.matlab); library(tidyverse)
#
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/pe_array.mat")
#
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/pe_array.mat")
dat[:,1:60]
dat[,1:60]
dat$merged.matrix(,1:60)
dat$merged.matrix[,1:60]
pe_mat <- dat$merged.matrix[,1:60]
group <- ifelse(pe_mat[,61],"sz","hc")
ifelse(dat$merged.matrix[,61],"sz","hc")
group <- ifelse(dat$merged.matrix[,61],"sz","hc")
task <- repmat(c(1,2,3),each=20)
task <- rep(c(1,2,3),each=20)
task
str(pe_mat)
str(group)
str(task)
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:52  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Check structure
str(long_pe)
head(long_pe)
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
library(lme4)
anova_model <- lmer(PE ~ Group * Task + (1|Subject), data = long_pe)
anova(anova_model)
# Loading libraries
library(R.matlab); library(tidyverse)
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/normalized_pe_array.mat")
pe_mat <- dat$merged.matrix[,1:60]
group <- ifelse(dat$merged.matrix[,61],"sz","hc")
task <- rep(c(1,2,3),each=20)
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:52  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Check structure
str(long_pe)
head(long_pe)
library(lme4)
anova_model <- lmer(PE ~ Group * Task + (1|Subject), data = long_pe)
anova(anova_model)
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
pe_mat
library(R.matlab); library(tidyverse)
#
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/pe_array.mat")
#dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/normalized_pe_array.mat")
pe_mat <- dat$merged.matrix[,1:60]
group <- ifelse(dat$merged.matrix[,61],"sz","hc")
task <- rep(c(1,2,3),each=20)
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:52  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Check structure
str(long_pe)
head(long_pe)
library(lme4)
anova_model <- lmer(PE ~ Group * Task + (1|Subject), data = long_pe)
anova(anova_model)
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/pe_array.mat")
#dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/normalized_pe_array.mat")
pe_mat <- dat$merged.matrix[,1:60]
group <- factor(ifelse(dat$merged.matrix[,61],"sz","hc"))
task <- factor(rep(c(1,2,3),each=20))
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:52  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Check structure
str(long_pe)
plot(density(long_pe$PE))
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
library(emmeans)
# Fit mixed ANOVA model again
library(lme4)
anova_model <- lmer(PE ~ Group * Task + (1|Subject), data = long_pe)
# Estimated Marginal Means (EMMs) for Task within each Group
task_emmeans <- emmeans(anova_model, pairwise ~ Task | Group, adjust = "bonferroni")
# Show pairwise comparisons
task_emmeans
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
summary(anova_model)
# Estimated Marginal Means (EMMs) for Task within each Group
task_emmeans <- emmeans(anova_model, pairwise ~ Task | Group, adjust = "bonferroni")
# Show pairwise comparisons
task_emmeans
task_emmeans <- emmeans(anova_model, pairwise ~ Group | Task, adjust = "bonferroni")
anova_model <- aov(PE ~ Group * Task + Error(Subject/Task), data = long_pe)
task_emmeans <- emmeans(anova_model, pairwise ~ Group , adjust = "bonferroni")
# Show pairwise comparisons
task_emmeans
summary(anova_model)
library(emmeans)
# Estimated Marginal Means (EMMs) for Task within each Group
task_emmeans <- emmeans(anova_model, pairwise ~ Task | Group, adjust = "bonferroni")
# Show pairwise comparisons
task_emmeans
load("/Volumes/HD-B1/EIB/Rho_Med.RData")
load("/Volumes/HD-B1/EIB/Rho_Med.RData")
load("/Volumes/HD-B1/EIB/Rho_Med.Rdata")
file.exists("/Volumes/HD-B1/EIB/Rho_Med.Rdata")
# Loading libraries
library(R.matlab); library(tidyverse)
setwd("/Users/kaankeskin/projects/sch_pe/")
#
dat <- readMat("./data/processed/pe_array.mat")
subj_table <- read.csv("./data/raw/subjects_list.csv")
#dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/normalized_pe_array.mat")
pe_mat <- dat$merged.matrix[,1:60]
group <- factor(ifelse(dat$merged.matrix[,61],"sz","hc"))
task <- factor(rep(c(1,2,3),each=20))
sex <- factor(ifelse(subj_table$sex,"M","F"))
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:52  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Add Sex information
long_pe$Sex <- rep(sex, times = ncol(pe_mat))  # Assign the correct task for each trial
library(R.matlab); library(tidyverse)
setwd("/Users/kaankeskin/projects/sch_pe/")
#
dat <- readMat("./data/processed/pe_array.mat")
subj_table <- read.csv("./data/raw/subjects_list.csv")
#dat <- readMat("/Users/kaankeskin/projects/sch_pe/data/processed/normalized_pe_array.mat")
pe_mat <- dat$merged.matrix[,1:60]
group <- factor(ifelse(dat$merged.matrix[,61],"sz","hc"))
task <- factor(rep(c(1,2,3),each=20))
sex <- factor(ifelse(subj_table$sex,"M","F"))
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:51  # Assign a unique ID to each subject
library(R.matlab); library(tidyverse)
setwd("/Users/kaankeskin/projects/sch_pe/")
#
dat <- readMat("./data/processed/pe_array.mat")
subj_table <- read.csv("./data/raw/subjects_list.csv")
subj_table
dat <- readMat("./data/processed/pe_array.mat")
dat
dat$merged.matrix[9,:]
dat$merged.matrix[9,]
sum(dat$merged.matrix[9,])
dat2 <- readMat("./data/processed/pe_array2.mat")
dat2$merged.matrix
subj_table <- read.csv("./data/raw/subjects_list.csv")
subj_table
library(R.matlab); library(tidyverse)
setwd("/Users/kaankeskin/projects/sch_pe/")
dat <- readMat("./data/processed/pe_array2.mat")
subj_table <- read.csv("./data/raw/subjects_list.csv")
pe_mat <- dat$merged.matrix[,1:60]
group <- factor(ifelse(dat$merged.matrix[,61],"sz","hc"))
task <- factor(rep(c(1,2,3),each=20))
sex <- factor(ifelse(subj_table$sex,"M","F"))
library(reshape2)
# Convert pe_mat to a data frame
pe_df <- as.data.frame(pe_mat)
# Add Subject IDs
pe_df$Subject <- 1:51  # Assign a unique ID to each subject
# Reshape to long format
long_pe <- melt(pe_df, id.vars = "Subject", variable.name = "Trial", value.name = "PE")
# Add Group information
long_pe$Group <- rep(group, times = ncol(pe_mat))  # Repeat for each column
# Add Task information
long_pe$Task <- rep(task, each = nrow(pe_mat))  # Assign the correct task for each trial
# Add Sex information
long_pe$Sex <- rep(sex, times = ncol(pe_mat))  # Assign the correct task for each trial
# Check structure
str(long_pe)
head(long_pe)
subj_table
T <- read.csv("./data/raw/response.csv")
T
subj_table
T$denekId %in% subj_table$subj
T[T$denekId %in% subj_table$subj,]
T_raw <- read.csv("./data/raw/response.csv")
T_raw[T_raw$denekId %in% subj_table$subj,]
T <- T_raw[T_raw$denekId %in% subj_table$subj,]
T
sum(T$sayac==59)
T_raw
T <- T_raw[T_raw$denekId %in% subj_table$task.id,]
sum(T$sayac==59)
T
sum(T$sayac==59)
# Just for control. Shoul equal to 51
#sum(T$sayac==59)
T[-id]
# Just for control. Shoul equal to 51
#sum(T$sayac==59)
head(T[,c(2,3,4,5)])
S
subj_table
rep(subj_table$group,each=60)
# Just for control. Shoul equal to 51
#sum(T$sayac==59)
T_last <- T[,c(2,3,4,5)]
T_last$group <- rep(subj_table$group,each=60)
head(T_last)
subj_table
T_last$phase <- cut(
T_last$sayac,
breaks = c(0,19,39,59),
labels = c("1", "2", "3"),
include.lowest = TRUE
)
T_last
head(T_last)
library(lme4)
model <- glmer(
yatirim ~ group * rakip * phase + (1 | subject),
data = df,
family = binomial(link = "logit")
)
library(lme4)
model <- glmer(
yatirim ~ group * rakip * phase + (1 | subject),
data = T_last,
family = binomial(link = "logit")
)
library(lme4)
model <- glmer(
yatirim ~ group * rakip * phase + (1 | denekId),
data = T_last,
family = binomial(link = "logit")
)
summary(model)
with(T_last, table(group, rakip, phase, yatirim))
factor(T$yatirim)
factor(T_last$yatirim)
T_last$yatirim <- factor(T_last$yatirim)
T_last$rakip <- factor(T_last$rakip)
T_last$group <- factor(T_last$group)
T_last$phase <- factor(T_last$phase)
model <- glmer(
yatirim ~ group * phase + (1 | denekId),
data = T_last,
family = binomial(link = "logit")
)
summary(model)
summary(model)
model <- glm(
yatirim ~ group * phase,
data = T_last,
family = binomial(link = "logit")
)
summary(model)
s
subj_table
subj_table <- subset(subj_table, !(subj %in% c(9, 44)))
subj_table
T_raw <- read.csv("./data/raw/response.csv")
T <- T_raw[T_raw$denekId %in% subj_table$task.id,]
T
T_last <- T[,c(2,3,4,5)]
T_last$group <- rep(subj_table$group,each=60)
T_last$phase <- cut(
T_last$sayac,
breaks = c(0,19,39,59),
labels = c("1", "2", "3"),
include.lowest = TRUE
)
library(lme4)
T_last$yatirim <- factor(T_last$yatirim)
T_last$rakip <- factor(T_last$rakip)
T_last$group <- factor(T_last$group)
T_last$phase <- factor(T_last$phase)
model <- glm(
yatirim ~ group * phase,
data = T_last,
family = binomial(link = "logit")
)
summary(model)
model <- glm(
yatirim ~ group * phase + (1 | denekId),
data = T_last,
family = binomial(link = "logit")
)
summary(model)
model <- glmer(
yatirim ~ group * phase + (1 | denekId),
data = T_last,
family = binomial(link = "logit")
)
summary(model)
subj_table <- read.csv("./data/raw/subjects_list.csv")
subj_table <- subset(subj_table, !(subj %in% c(24, 44)))
T_raw <- read.csv("./data/raw/response.csv")
T <- T_raw[T_raw$denekId %in% subj_table$task.id,]
# Just for control. Shoul equal to 51
#sum(T$sayac==59)
T_last <- T[,c(2,3,4,5)]
T_last$group <- rep(subj_table$group,each=60)
T_last$phase <- cut(
T_last$sayac,
breaks = c(0,19,39,59),
labels = c("1", "2", "3"),
include.lowest = TRUE
)
T_last
library(lme4)
T_last$yatirim <- factor(T_last$yatirim)
T_last$rakip <- factor(T_last$rakip)
T_last$group <- factor(T_last$group)
T_last$phase <- factor(T_last$phase)
model <- glm(
yatirim ~ group * phase ,
data = T_last,
family = binomial(link = "logit")
)
summary(model)
subj_table
