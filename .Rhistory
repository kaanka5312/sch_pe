library(ggseg)
library(ggseg) ; library(ggsegGlasser) ; library(rethinking); library(tidyverse)
someData <- tibble(
region = rep(c("transverse temporal", "insula",
"precentral","superior parietal"), 2),
p = sample(seq(0,.5,.001), 8),
groups = c(rep("g1", 4), rep("g2", 4))
)
someData %>%
group_by(groups) %>%
ggplot() +
geom_brain(atlas = dk,
position = position_brain(hemi ~ side),
aes(fill = p)) +
facet_wrap(~groups)
group12 <- tibble(
region = c("superior frontal", "superior frontal","pars opercularis", "pars opercularis","pars triangularis", "precentral", "precentral", "paracentral", "superior temporal"),
t = c(2.719,2.422,2.394,2.626,2.298,4.413,2.674,2.834,2.907),
hemisphere = c("R", "L", "R", "L","R", "R", "L", "R", "R", "R")
)
group12 <- tibble(
region = c("superior frontal", "superior frontal","pars opercularis", "pars opercularis","pars triangularis", "precentral", "precentral", "paracentral", "superior temporal"),
t = c(2.719,2.422,2.394,2.626,2.298,4.413,2.674,2.834,2.907),
hemisphere = c("R", "L", "R", "L","R", "R", "L", "R", "R")
)
p1 <- group12 %>%
group_by(hemisphere)  %>%
ggplot() +
geom_brain(atlas = dk,
position = position_brain(hemi ~ side),
aes(fill = t)) +
ggtitle("Iyi Yanit > Kotu Yanit")+
mytheme +
scale_fill_gradient(low = "gray", high="black", na.value = "white",limits=c(2.2,4.5))+
facet_wrap(~hemisphere)
mytheme <- theme_classic()+
theme(legend.position = "bottom",
legend.text = element_text(size = 10),
axis.line = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.ticks.y = element_blank(),
axis.text.y = element_blank(),
plot.title = element_text(size = 20, face = "bold", hjust = 0.5))
group12 <- tibble(
region = c("superior frontal", "superior frontal","pars opercularis", "pars opercularis","pars triangularis", "precentral", "precentral", "paracentral", "superior temporal"),
t = c(2.719,2.422,2.394,2.626,2.298,4.413,2.674,2.834,2.907),
hemisphere = c("R", "L", "R", "L","R", "R", "L", "R", "R")
)
p1 <- group12 %>%
group_by(hemisphere)  %>%
ggplot() +
geom_brain(atlas = dk,
position = position_brain(hemi ~ side),
aes(fill = t)) +
ggtitle("Iyi Yanit > Kotu Yanit")+
mytheme +
scale_fill_gradient(low = "gray", high="black", na.value = "white",limits=c(2.2,4.5))+
facet_wrap(~hemisphere)
p1
ggarrange(p1,ncol = 1, common.legend = TRUE
)%>%ggpubr::ggexport(filename = "/Users/kaank/OneDrive/Belgeler/elif_figure2.png",width = 800,height = 400,res=150)
library(ggpubr)
ggarrange(p1,ncol = 1, common.legend = TRUE
)%>%ggpubr::ggexport(filename = "/Users/kaank/OneDrive/Belgeler/elif_figure2.png",width = 800,height = 400,res=150)
p1%>%ggpubr::ggexport(filename = "/Users/kaank/OneDrive/Belgeler/elif_figure2.png",width = 800,height = 400,res=150)
key %>% filter(BCNatlas=="120")
library(readxl)
key <- read_xlsx(paste0(source_path,"/DATA/myDataParcels.xlsx"))
# source_path = "C:/Users/kaan/Documents/MultGroup_WC"
source_path = "C:/Users/kaank/OneDrive/Belgeler/GitHub/MultGroup_WC"
library(readxl)
key <- read_xlsx(paste0(source_path,"/DATA/myDataParcels.xlsx"))
HC <- read.table(file = paste0(source_path,"/DATA/HC.csv"),sep=",")
BP <- read.table(file = paste0(source_path,"/DATA/BP.csv"),sep=",")
MDD <- read.table(file = paste0(source_path,"/DATA/MDD.csv"),sep=",")
Manic <- read.table(file = paste0(source_path,"/DATA/Manic.csv"),sep=",")
subject_list <- list(HC, BP, MDD, Manic)
roi_list<- lapply(subject_list, colMeans)
# Add ROI values to the `key` tibble
average_by_bcnatlas <- function(roi_vector, key) {
key %>%
mutate(ROI_value = roi_vector) %>%        # Add the ROI vector as a column
group_by(BCNatlas) %>%                   # Group by BCNatlas
summarize(Average_ROI = mean(ROI_value, na.rm = TRUE)) # Calculate the average
}
# Apply the function to each vector in the list
averaged_rois_list <- lapply(roi_list, average_by_bcnatlas, key = key)
library(tidyverse)
HC <- read.table(file = paste0(source_path,"/DATA/HC.csv"),sep=",")
BP <- read.table(file = paste0(source_path,"/DATA/BP.csv"),sep=",")
MDD <- read.table(file = paste0(source_path,"/DATA/MDD.csv"),sep=",")
Manic <- read.table(file = paste0(source_path,"/DATA/Manic.csv"),sep=",")
subject_list <- list(HC, BP, MDD, Manic)
roi_list<- lapply(subject_list, colMeans)
# Add ROI values to the `key` tibble
average_by_bcnatlas <- function(roi_vector, key) {
key %>%
mutate(ROI_value = roi_vector) %>%        # Add the ROI vector as a column
group_by(BCNatlas) %>%                   # Group by BCNatlas
summarize(Average_ROI = mean(ROI_value, na.rm = TRUE)) # Calculate the average
}
# Apply the function to each vector in the list
averaged_rois_list <- lapply(roi_list, average_by_bcnatlas, key = key)
# View results for the first vector
print(averaged_rois_list[[1]])
#### Testing if regions are belonged to core or periphery ####
transmodal <- ifelse(NeuroMyelFC::trans_nonself | NeuroMyelFC::trans_self,1,0)
key <- key %>%
mutate(Category = transmodal)
# Check consistency for each BCNatlas group
consistency_check <- key %>%
group_by(BCNatlas) %>%
summarize(
Is_Consistent = if (n_distinct(Category) == 1) "YES" else "NO" # TRUE if all categories are the same
)
# View results
print(consistency_check)
key %>% filter(BCNatlas=="120")
key %>% filter(BCNatlas=="121")
key
#### Organizing the connectivity matrix
dat <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_dti_connectivity.csv",row.names = 1)
#### Organizing the connectivity matrix
dat <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_dti_connectivity",row.names = 1)
dat
dat <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_dti_connectivity",
sep="\t",
header = TRUE,
row.names = 1)
dat
dat <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_dti_connectivity",
sep="\t",
check.names = FALSE,
header = TRUE,
row.names = 1)
dat
dat <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_dti_connectivity",
sep="\t",
check.names = FALSE,
header = TRUE,
row.names = 1)
key <- read_xlsx(paste0(source_path,"/DATA/myDataParcels.xlsx"))
HC <- read.table(file = paste0(source_path,"/DATA/HC.csv"),sep=",")
BP <- read.table(file = paste0(source_path,"/DATA/BP.csv"),sep=",")
MDD <- read.table(file = paste0(source_path,"/DATA/MDD.csv"),sep=",")
Manic <- read.table(file = paste0(source_path,"/DATA/Manic.csv"),sep=",")
subject_list <- list(HC, BP, MDD, Manic)
roi_list<- lapply(subject_list, colMeans)
# Add ROI values to the `key` tibble
average_by_bcnatlas <- function(roi_vector, key) {
key %>%
mutate(ROI_value = roi_vector) %>%        # Add the ROI vector as a column
group_by(BCNatlas) %>%                   # Group by BCNatlas
summarize(Average_ROI = mean(ROI_value, na.rm = TRUE)) # Calculate the average
}
# Apply the function to each vector in the list
averaged_rois_list <- lapply(roi_list, average_by_bcnatlas, key = key)
# View results for the first vector
print(averaged_rois_list[[1]])
subject_list
key
averaged_rois_list
Cmat <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_dti_connectivity",
sep="\t",
check.names = FALSE,
header = TRUE,
row.names = 1)
Cmat
# Normalize by the maximum value
Cmat_max <- Cmat / max(Cmat)
# Check the normalized matrix
print(Cmat_max)
# View results for the first vector
print(averaged_rois_list[[1]])
read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_roivoxels",
sep="\t",
check.names = FALSE,
header = TRUE,
row.names = 1)
### ROI normalization ###
roilist <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_roivoxels",
sep="\t",
check.names = FALSE,
header = TRUE,
row.names = 1)
roi_list
roilist <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_roivoxels",
sep="\t",
check.names = FALSE,
header = TRUE,
row.names = 1)
roilist
roilist
roilist
roilist[1]
roilist[1,1]
ro
roilist[612:617,]
roilist <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_roivoxels",
sep="\t",
check.names = FALSE,
header = TRUE,
row.names = 1)
roilist
roilist <- read.csv("C:/Users/kaank/Downloads/dti_connectivity/sub-2_roivoxels",
sep="\t",
check.names = FALSE,
header = FALSE,
row.names = 1)
roilist
roilist[612,]
roilist[1,]
roilist[612,]
# List of regions to select
regions <- c("R. transverse temporal gyrus", "R. superior temporal gyrus (gm)")
# Filter rows based on the region names in column V2
selected_voxels <- roilist[roilist$V2 %in% regions, "V3"]
# Display the result
print(selected_voxels)
# List of regions to select
regions <- c("R. transverse temporal gyrus (gm)", "R. superior temporal gyrus (gm)")
# Filter rows based on the region names in column V2
selected_voxels <- roilist[roilist$V2 %in% regions, "V3"]
# Display the result
print(selected_voxels)
key
averaged_rois_list
print(averaged_rois_list[[1]],n=59)
library(readxl)
key <- read_xlsx(paste0(source_path,"/DATA/myDataParcels.xlsx"))
HC <- read.table(file = paste0(source_path,"/DATA/HC.csv"),sep=",")
BP <- read.table(file = paste0(source_path,"/DATA/BP.csv"),sep=",")
MDD <- read.table(file = paste0(source_path,"/DATA/MDD.csv"),sep=",")
Manic <- read.table(file = paste0(source_path,"/DATA/Manic.csv"),sep=",")
subject_list <- list(HC, BP, MDD, Manic)
roi_list<- lapply(subject_list, colMeans)
# Add ROI values to the `key` tibble
average_by_bcnatlas <- function(roi_vector, key) {
key %>%
mutate(ROI_value = roi_vector) %>%        # Add the ROI vector as a column
group_by(BCNatlas) %>%                   # Group by BCNatlas
summarize(Average_ROI = mean(ROI_value, na.rm = TRUE)) # Calculate the average
}
# Apply the function to each vector in the list
averaged_rois_list <- lapply(roi_list, average_by_bcnatlas, key = key)
# View results for the first vector
print(averaged_rois_list[[1]])
print(averaged_rois_list[[1]],n=58)
library(ggseg)
library(ggsegGlasser)
glasser
ggplot() + geom_brain()
ggsegGlasser::glasser
ggplot() + geom_brain( atlas = glasser)
ggplot() + geom_brain( atlas = glasser,
show.legend = FALSE,
position=position_brain(position= hemi ~ side),
mapping = aes(fill = "6d") )
ggplot() + geom_brain( atlas = glasser)
library(reticulate)
library(NeuroMyelFC)
# Set the Python path (adjust the path to your Python executable)
# Use the specific Python executable
#use_python("C:/Users/kaank/AppData/Local/Programs/Python/Python311/python.exe")
source_folder = "C:/Users/kaank/OneDrive/Belgeler/GitHub/MultGroup_WC/"
Sys.setenv(RETICULATE_PYTHON = "C:/Users/kaank/miniconda3/envs/multgroup/python.exe")
library(reticulate)
np <- import("numpy")
array <- np$load(paste(source_folder,"group_freekgl3.npy",sep=""),allow_pickle = TRUE)
merged_matrices <- list()
# Get the names from the list
array_names <- names(array[[1]])
# Loop through each name in the list
for (name in array_names) {
# Initialize empty matrices to store the merged results for each name
merged_acw_static_firing_matrix <- NULL
merged_acw_dynamic_firing_matrix <- NULL
merged_acw_static_fmri_matrix <- NULL
merged_gscorr_fmri_matrix <- NULL
merged_gscorr_firing_matrix <- NULL
# Loop through each element in the sublist
for (i in 1:length(array[[1]]$MDD)) {
merged_acw_static_firing_matrix <- rbind(merged_acw_static_firing_matrix, array[[1]][[name]][[i]]$acw_static_firing_matrix)
merged_acw_dynamic_firing_matrix <- rbind(merged_acw_dynamic_firing_matrix, array[[1]][[name]][[i]]$acw_dynamic_firing_matrix)
merged_acw_static_fmri_matrix <- rbind(merged_acw_static_fmri_matrix, array[[1]][[name]][[i]]$acw_static_fmri_matrix)
merged_gscorr_fmri_matrix <- rbind(merged_gscorr_fmri_matrix, array[[1]][[name]][[i]]$gscorr_fmri_matrix)
merged_gscorr_firing_matrix <- rbind(merged_gscorr_firing_matrix, array[[1]][[name]][[i]]$gscorr_firing_matrix)
}
# Save the merged matrices into the final list
merged_matrices[[name]] <- list(
merged_acw_static_firing_matrix = merged_acw_static_firing_matrix,
merged_acw_dynamic_firing_matrix = merged_acw_dynamic_firing_matrix,
merged_acw_static_fmri_matrix = merged_acw_static_fmri_matrix,
merged_gscorr_fmri_matrix = merged_gscorr_fmri_matrix,
merged_gscorr_firing_matrix = merged_gscorr_firing_matrix
)
}
gs_sim = list()
gs_sim$mdd = merged_matrices$MDD$merged_gscorr_fmri_matrix
gs_sim$hc = merged_matrices$HC$merged_gscorr_fmri_matrix
gs_sim$manic = merged_matrices$Manic$merged_gscorr_fmri_matrix
gs_sim$bp = merged_matrices$BP$merged_gscorr_fmri_matrix
uni <- NeuroMyelFC::uni_nonself | NeuroMyelFC::uni_self
trans <- NeuroMyelFC::trans_nonself | NeuroMyelFC::trans_self
gs_sim
dat <- lapply(gs_sim, function(mat){
masked_mat <- mat[, uni, drop = FALSE]  # Apply the mask to select columns
rowMeans(masked_mat)                    # Compute row-wise means for selected columns
})
sim_uni <- data.frame(
value=c(dat$hc,dat$mdd,dat$manic,dat$bp),
group = c(rep(c("hc","mdd","manic","bp"),each=90))
)
sim_uni
anova_result <- aov(value~group,data=sim_uni)
TukeyHSD(anova_result)
ggplot(sim_uni,aes( x = group, y = value)) +
geom_boxplot() +
theme_minimal() +
ggtitle("Unimodal - Simulation")
dat <- lapply(gs_sim, function(mat){
masked_mat <- mat[, trans, drop = FALSE]  # Apply the mask to select columns
rowMeans(masked_mat)                    # Compute row-wise means for selected columns
})
sim_trans <- data.frame(
value=c(dat$hc,dat$mdd,dat$manic,dat$bp),
group = c(rep(c("hc","mdd","manic","bp"),each=90))
)
anova_result <- aov(value~group,data=sim_trans)
summary(anova_result) # report
anova_result <- aov(value~group,data=sim_trans)
TukeyHSD(anova_result)
summary(anova_result) # report
ggplot(sim_trans,aes( x = group, y = value)) +
geom_boxplot() +
theme_minimal() +
ggtitle("Transmodal - Simulation")
sim_trans
dat <- lapply(gs_sim, function(mat){
masked_mat <- mat[, trans, drop = FALSE]  # Apply the mask to select columns
rowMeans(masked_mat)                    # Compute row-wise means for selected columns
})
sim_trans <- data.frame(
value=c(dat$hc,dat$mdd,dat$manic,dat$bp),
group = c(rep(c("hc","mdd","manic","bp"),each=90))
)
sim_trans
anova_result <- aov(value~group,data=sim_trans)
TukeyHSD(anova_result)
# Load the package
library(effectsize)
# Calculate eta squared
eta_squared(anova_result)
anova_result
TukeyHSD(anova_result)
summary(anova_result)
anova_result <- aov(value~group,data=sim_uni)
TukeyHSD(anova_result)
ggplot(sim_uni,aes( x = group, y = value)) +
geom_boxplot() +
theme_minimal()
array1<-c(39,33,14,32,10,50,47,30,34,50,37,42,47,44,50,33,46,28,46,29,49,33,54,31,37,35
)
array2 <- c(48,34,51,35,25,25,46,22,8,38,52,28,10,37,27,24)
kruskal.test(array1,array2)
shapiro.test(array1)
shapiro.test(array2)
t_test_result <- t.test(array1, array2, var.equal = FALSE)
print(t_test_result)
# Loading libraries
library(R.matlab); library(tidyverse)
setwd("/Users/kaankeskin/projects/sch_pe/")
library(R.matlab); library(tidyverse)
#setwd("/Users/kaankeskin/projects/sch_pe/")
# Microsoft
setwd("C:/Users/kaank/OneDrive/Belgeler/GitHub/sch_pe/")
#
dat <- readMat("./data/processed/pe_array2.mat")
subj_table <- read.csv("./data/raw/subjects_list.csv")
subj_table <- subset(subj_table, !(subj %in% c(9, 44)))
T_raw <- read.csv("./data/raw/response.csv")
T <- T_raw[T_raw$denekId %in% subj_table$task.id,]
# Just for control. Shoul equal to 51
#sum(T$sayac==59)
T_last <- T[,c(2,3,4,5)]
T_last$group <- rep(subj_table$group,each=60)
T_last$phase <- cut(
T_last$sayac,
breaks = c(0,19,39,59),
labels = c("1", "2", "3"),
include.lowest = TRUE
)
library(lme4)
T_last$yatirim <- factor(T_last$yatirim)
T_last$rakip <- factor(T_last$rakip)
T_last$group <- factor(T_last$group)
T_last$phase <- factor(T_last$phase)
# Create a 2x2 table for each group
tables <- by(T_last, T_last$group, function(sub_df) table(sub_df$yatirim, sub_df$rakip))
# Display tables
tables
# Logistic regression model
model <- glm(yatirim ~ group * rakip, data = T_last, family = binomial)
# Display model summary
summary(model)
model <- glm(
yatirim ~ group * phase * rakip,  # Adds main effects & all interactions
data = T_last,
family = binomial(link = "logit")
)
summary(model)
model <- glm(
yatirim ~ group * phase ,
data = T_last,
family = binomial(link = "logit")
)
summary(model)
model_simpler <- glm(
yatirim ~ group + phase + rakip + group:rakip,  # Focuses on group Ã— rakip interaction
data = T_last,
family = binomial(link = "logit")
)
summary(model_simpler)
T_last$yatirim
T_last$rakip
# Create a 2x2 table for each group
tables <- by(T_last, T_last$group, function(sub_df) table(sub_df$yatirim, sub_df$rakip))
# Display tables
tables
help(table)
# Create a 2x2 table for each group
tables <- by(T_last, T_last$group, function(sub_df) table(yatirim = sub_df$yatirim, rakip = sub_df$rakip))
# Display tables
tables
# Create dummy variables
T_last$yatirim1_rakip1 <- ifelse(T_last$yatirim == 1 & T_last$rakip == 1, 1, 0)
T_last$yatirim1_rakip0 <- ifelse(T_last$yatirim == 1 & T_last$rakip == 0, 1, 0)
T_last$yatirim0_rakip1 <- ifelse(T_last$yatirim == 0 & T_last$rakip == 1, 1, 0)
model_dummies <- glm(
yatirim ~ group * phase + yatirim1_rakip1 + yatirim1_rakip0 + yatirim0_rakip1,
data = T_last,
family = binomial(link = "logit")
)
summary(model_dummies)
T_last$yatirim == 0 & T_last$rakip == 1
T_last %>% filter(yatirim == 0)
model_dummies <- glm(
yatirim ~ group * phase + yatirim1_rakip1 + yatirim1_rakip0 + yatirim0_rakip1,
data = T_last,
family = binomial(link = "logit")
)
summary(model_dummies)
T_last <- T_last %>%
arrange(subject, trial) %>%  # Ensure data is ordered by subject and trial
group_by(subject) %>%
mutate(cum_rakip = cumsum(lag(rakip, default = 0))) %>%  # Cumulative sum of previous rakip values
ungroup()
head(T_last)
T_last <- T_last %>%
arrange(denekId, sayac) %>%  # Ensure data is ordered by subject and trial
group_by(denekID) %>%
mutate(cum_rakip = cumsum(lag(rakip, default = 0))) %>%  # Cumulative sum of previous rakip values
ungroup()
T_last
T_last %>%
arrange(denekId, sayac)
T_last %>%
arrange(denekId, sayac) %>%  # Ensure data is ordered by subject and trial
group_by(denekID)
T_last <- T_last %>%
arrange(denekId, sayac) %>%  # Ensure data is ordered by subject and trial
group_by(denekId) %>%
mutate(cum_rakip = cumsum(lag(rakip, default = 0))) %>%  # Cumulative sum of previous rakip values
ungroup()
T_last <- T_last %>%
arrange(denekId, sayac) %>%  # Ensure data is ordered by subject and trial
group_by(denekId) %>%  # Group by subject
mutate(cum_rakip = cumsum(lag(as.numeric(as.character(rakip)), default = 0))) %>%  # Convert rakip to numeric
ungroup()
T_last
T_last$cum_rakip
head(T_last)
T_raw <- read.csv("./data/raw/response.csv")
T <- T_raw[T_raw$denekId %in% subj_table$task.id,]
# Just for control. Shoul equal to 51
#sum(T$sayac==59)
T_last <- T[,c(2,3,4,5)]
T_last$group <- rep(subj_table$group,each=60)
T_last$phase <- cut(
T_last$sayac,
breaks = c(0,19,39,59),
labels = c("1", "2", "3"),
include.lowest = TRUE
)
T_last$yatirim <- factor(T_last$yatirim)
T_last$group <- factor(T_last$group)
T_last$phase <- factor(T_last$phase)
T_last <- T_last %>%
arrange(denekId, sayac) %>%  # Ensure data is ordered by subject and trial
group_by(denekId) %>%
mutate(cum_rakip = cumsum(lag(rakip, default = 0))) %>%  # Cumulative sum of previous rakip values
ungroup()
T_last
T_last %>% filter(denekId==8)
View(T_last %>% filter(denekId==8))
model_cum_rakip <- glm(
yatirim ~ group * phase + cum_rakip + group:cum_rakip,
data = T_last,
family = binomial(link = "logit")
)
summary(model_cum_rakip)
